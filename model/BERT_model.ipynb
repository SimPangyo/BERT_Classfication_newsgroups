{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_model",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bheDWU78V1HQ",
        "outputId": "5f07cfd7-222c-462c-8dea-929b70a54144"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.9.2-py3-none-any.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 52.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 73.1 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.12\n",
            "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 63.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.12 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58vRz_T75LHE"
      },
      "source": [
        "import pickle \n",
        "from transformers import TFBertModel\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras import optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "\n",
        "with open('/content/drive/MyDrive/news20_train_data.pkl', 'rb') as f:\n",
        "  x_train_ids, x_train_msk, x_train_typ, x_test_ids, x_test_msk, x_test_typ, y_train, y_test=pickle.load(f)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXh0dDtP-PmO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4e51906-a404-457c-96a3-8cb599a05723"
      },
      "source": [
        "bert_model = TFBertModel.from_pretrained('bert-base-uncased', cache_dir='bert_eng_ckpt')\n",
        "bert_model.summary()\n",
        "\n",
        "bert_model.trainable = False\n",
        "bert_model.summary() \n",
        "\n",
        "MAX_LEN = 20\n",
        "n_topic = len(y_train)\n",
        "\n",
        "x_input_ids = Input(batch_shape = (None, MAX_LEN), dtype = tf.int32)\n",
        "x_input_msk = Input(batch_shape = (None, MAX_LEN), dtype = tf.int32)\n",
        "x_input_typ = Input(batch_shape = (None, MAX_LEN), dtype = tf.int32)\n",
        "\n",
        "output_bert = bert_model([x_input_ids, x_input_msk, x_input_typ])\n",
        "y_output = Dense(n_topic, activation = 'softmax')(output_bert[1])\n",
        "model = Model([x_input_ids, x_input_msk, x_input_typ], y_output)\n",
        "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = Adam(learning_rate = 0.01))\n",
        "model.summary()\n",
        "\n",
        "output_bert"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"tf_bert_model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bert (TFBertMainLayer)       multiple                  109482240 \n",
            "=================================================================\n",
            "Total params: 109,482,240\n",
            "Trainable params: 109,482,240\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"tf_bert_model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bert (TFBertMainLayer)       multiple                  109482240 \n",
            "=================================================================\n",
            "Total params: 109,482,240\n",
            "Trainable params: 0\n",
            "Non-trainable params: 109,482,240\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_8 (InputLayer)            [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_9 (InputLayer)            [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model_2 (TFBertModel)   TFBaseModelOutputWit 109482240   input_7[0][0]                    \n",
            "                                                                 input_8[0][0]                    \n",
            "                                                                 input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 6907)         5311483     tf_bert_model_2[0][1]            \n",
            "==================================================================================================\n",
            "Total params: 114,793,723\n",
            "Trainable params: 5,311,483\n",
            "Non-trainable params: 109,482,240\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TFBaseModelOutputWithPooling([('last_hidden_state',\n",
              "                               <KerasTensor: shape=(None, 20, 768) dtype=float32 (created by layer 'tf_bert_model_2')>),\n",
              "                              ('pooler_output',\n",
              "                               <KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'tf_bert_model_2')>)])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DlepnNpXmIv",
        "outputId": "3cbbd386-97f6-4e1a-81af-ebe58be1c1a0"
      },
      "source": [
        "x_train = [x_train_ids, x_train_msk, x_train_typ]\n",
        "x_test = [x_test_ids, x_test_msk, x_test_typ]\n",
        "hist = model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs=100, batch_size=512)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "14/14 [==============================] - ETA: 0s - loss: 3.4580WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "14/14 [==============================] - 28s 909ms/step - loss: 3.4580 - val_loss: 2.8742\n",
            "Epoch 2/100\n",
            "14/14 [==============================] - 11s 757ms/step - loss: 2.7066 - val_loss: 2.5379\n",
            "Epoch 3/100\n",
            "14/14 [==============================] - 11s 783ms/step - loss: 2.5103 - val_loss: 2.3612\n",
            "Epoch 4/100\n",
            "14/14 [==============================] - 11s 782ms/step - loss: 2.3610 - val_loss: 2.3096\n",
            "Epoch 5/100\n",
            "14/14 [==============================] - 11s 765ms/step - loss: 2.2480 - val_loss: 2.2068\n",
            "Epoch 6/100\n",
            "14/14 [==============================] - 10s 749ms/step - loss: 2.1668 - val_loss: 2.0762\n",
            "Epoch 7/100\n",
            "14/14 [==============================] - 10s 738ms/step - loss: 2.1042 - val_loss: 1.9998\n",
            "Epoch 8/100\n",
            "14/14 [==============================] - 10s 734ms/step - loss: 2.0324 - val_loss: 1.9429\n",
            "Epoch 9/100\n",
            "14/14 [==============================] - 10s 735ms/step - loss: 1.9958 - val_loss: 1.8847\n",
            "Epoch 10/100\n",
            "14/14 [==============================] - 10s 739ms/step - loss: 1.9353 - val_loss: 1.8887\n",
            "Epoch 11/100\n",
            "14/14 [==============================] - 10s 747ms/step - loss: 1.9125 - val_loss: 1.8387\n",
            "Epoch 12/100\n",
            "14/14 [==============================] - 10s 753ms/step - loss: 1.8799 - val_loss: 1.7896\n",
            "Epoch 13/100\n",
            "14/14 [==============================] - 10s 751ms/step - loss: 1.8550 - val_loss: 1.7758\n",
            "Epoch 14/100\n",
            "14/14 [==============================] - 10s 750ms/step - loss: 1.8145 - val_loss: 1.7755\n",
            "Epoch 15/100\n",
            "14/14 [==============================] - 10s 748ms/step - loss: 1.7987 - val_loss: 1.7840\n",
            "Epoch 16/100\n",
            "14/14 [==============================] - 10s 746ms/step - loss: 1.7972 - val_loss: 1.7479\n",
            "Epoch 17/100\n",
            "14/14 [==============================] - 10s 747ms/step - loss: 1.7557 - val_loss: 1.7630\n",
            "Epoch 18/100\n",
            "14/14 [==============================] - 10s 746ms/step - loss: 1.7841 - val_loss: 1.7019\n",
            "Epoch 19/100\n",
            "14/14 [==============================] - 10s 746ms/step - loss: 1.7564 - val_loss: 1.7151\n",
            "Epoch 20/100\n",
            "14/14 [==============================] - 10s 746ms/step - loss: 1.7310 - val_loss: 1.6274\n",
            "Epoch 21/100\n",
            "14/14 [==============================] - 10s 743ms/step - loss: 1.7137 - val_loss: 1.6381\n",
            "Epoch 22/100\n",
            "14/14 [==============================] - 10s 742ms/step - loss: 1.6895 - val_loss: 1.7174\n",
            "Epoch 23/100\n",
            "14/14 [==============================] - 10s 745ms/step - loss: 1.6903 - val_loss: 1.5950\n",
            "Epoch 24/100\n",
            "14/14 [==============================] - 10s 744ms/step - loss: 1.6537 - val_loss: 1.5777\n",
            "Epoch 25/100\n",
            "14/14 [==============================] - 10s 746ms/step - loss: 1.6225 - val_loss: 1.5903\n",
            "Epoch 26/100\n",
            "14/14 [==============================] - 10s 746ms/step - loss: 1.6373 - val_loss: 1.6698\n",
            "Epoch 27/100\n",
            "14/14 [==============================] - 10s 744ms/step - loss: 1.6625 - val_loss: 1.5637\n",
            "Epoch 28/100\n",
            "14/14 [==============================] - 10s 746ms/step - loss: 1.6227 - val_loss: 1.5634\n",
            "Epoch 29/100\n",
            "14/14 [==============================] - 10s 745ms/step - loss: 1.5950 - val_loss: 1.5613\n",
            "Epoch 30/100\n",
            "14/14 [==============================] - 10s 747ms/step - loss: 1.5970 - val_loss: 1.5467\n",
            "Epoch 31/100\n",
            "14/14 [==============================] - 10s 746ms/step - loss: 1.5632 - val_loss: 1.4978\n",
            "Epoch 32/100\n",
            "14/14 [==============================] - 10s 745ms/step - loss: 1.5693 - val_loss: 1.5547\n",
            "Epoch 33/100\n",
            "14/14 [==============================] - 10s 747ms/step - loss: 1.5877 - val_loss: 1.5017\n",
            "Epoch 34/100\n",
            "14/14 [==============================] - 10s 745ms/step - loss: 1.5655 - val_loss: 1.5038\n",
            "Epoch 35/100\n",
            "14/14 [==============================] - 10s 746ms/step - loss: 1.5608 - val_loss: 1.5404\n",
            "Epoch 36/100\n",
            "14/14 [==============================] - 10s 746ms/step - loss: 1.5654 - val_loss: 1.5544\n",
            "Epoch 37/100\n",
            "14/14 [==============================] - 10s 746ms/step - loss: 1.5451 - val_loss: 1.5185\n",
            "Epoch 38/100\n",
            "14/14 [==============================] - 10s 743ms/step - loss: 1.5255 - val_loss: 1.4922\n",
            "Epoch 39/100\n",
            "14/14 [==============================] - 10s 745ms/step - loss: 1.5379 - val_loss: 1.5287\n",
            "Epoch 40/100\n",
            "14/14 [==============================] - 10s 745ms/step - loss: 1.5284 - val_loss: 1.4975\n",
            "Epoch 41/100\n",
            "14/14 [==============================] - 10s 745ms/step - loss: 1.5162 - val_loss: 1.4744\n",
            "Epoch 42/100\n",
            "14/14 [==============================] - 10s 747ms/step - loss: 1.5062 - val_loss: 1.4288\n",
            "Epoch 43/100\n",
            "14/14 [==============================] - 10s 746ms/step - loss: 1.5051 - val_loss: 1.5045\n",
            "Epoch 44/100\n",
            "14/14 [==============================] - 10s 745ms/step - loss: 1.5021 - val_loss: 1.4235\n",
            "Epoch 45/100\n",
            "14/14 [==============================] - 10s 749ms/step - loss: 1.4697 - val_loss: 1.4644\n",
            "Epoch 46/100\n",
            "14/14 [==============================] - 10s 747ms/step - loss: 1.4898 - val_loss: 1.4470\n",
            "Epoch 47/100\n",
            "14/14 [==============================] - 10s 748ms/step - loss: 1.4914 - val_loss: 1.4472\n",
            "Epoch 48/100\n",
            "14/14 [==============================] - 10s 748ms/step - loss: 1.4622 - val_loss: 1.4445\n",
            "Epoch 49/100\n",
            "14/14 [==============================] - 10s 748ms/step - loss: 1.4828 - val_loss: 1.4170\n",
            "Epoch 50/100\n",
            "14/14 [==============================] - 10s 750ms/step - loss: 1.4787 - val_loss: 1.4116\n",
            "Epoch 51/100\n",
            "14/14 [==============================] - 10s 750ms/step - loss: 1.4655 - val_loss: 1.4147\n",
            "Epoch 52/100\n",
            "14/14 [==============================] - 10s 752ms/step - loss: 1.4422 - val_loss: 1.3937\n",
            "Epoch 53/100\n",
            "14/14 [==============================] - 10s 750ms/step - loss: 1.4470 - val_loss: 1.3813\n",
            "Epoch 54/100\n",
            "14/14 [==============================] - 10s 751ms/step - loss: 1.4354 - val_loss: 1.3861\n",
            "Epoch 55/100\n",
            "14/14 [==============================] - 10s 750ms/step - loss: 1.4257 - val_loss: 1.4154\n",
            "Epoch 56/100\n",
            "14/14 [==============================] - 10s 750ms/step - loss: 1.4218 - val_loss: 1.3934\n",
            "Epoch 57/100\n",
            "14/14 [==============================] - 10s 750ms/step - loss: 1.4518 - val_loss: 1.3565\n",
            "Epoch 58/100\n",
            "14/14 [==============================] - 10s 749ms/step - loss: 1.4101 - val_loss: 1.3932\n",
            "Epoch 59/100\n",
            "14/14 [==============================] - 10s 749ms/step - loss: 1.4719 - val_loss: 1.4578\n",
            "Epoch 60/100\n",
            "14/14 [==============================] - 10s 748ms/step - loss: 1.4671 - val_loss: 1.4460\n",
            "Epoch 61/100\n",
            "14/14 [==============================] - 10s 750ms/step - loss: 1.4429 - val_loss: 1.4078\n",
            "Epoch 62/100\n",
            "14/14 [==============================] - 10s 748ms/step - loss: 1.4111 - val_loss: 1.3747\n",
            "Epoch 63/100\n",
            "14/14 [==============================] - 10s 750ms/step - loss: 1.4308 - val_loss: 1.3287\n",
            "Epoch 64/100\n",
            "14/14 [==============================] - 10s 749ms/step - loss: 1.4039 - val_loss: 1.3944\n",
            "Epoch 65/100\n",
            "14/14 [==============================] - 10s 748ms/step - loss: 1.4035 - val_loss: 1.4770\n",
            "Epoch 66/100\n",
            "14/14 [==============================] - 10s 749ms/step - loss: 1.4097 - val_loss: 1.3610\n",
            "Epoch 67/100\n",
            "14/14 [==============================] - 10s 750ms/step - loss: 1.4080 - val_loss: 1.3502\n",
            "Epoch 68/100\n",
            "14/14 [==============================] - 10s 749ms/step - loss: 1.4047 - val_loss: 1.4143\n",
            "Epoch 69/100\n",
            "14/14 [==============================] - 10s 750ms/step - loss: 1.3842 - val_loss: 1.3655\n",
            "Epoch 70/100\n",
            "14/14 [==============================] - 10s 749ms/step - loss: 1.4034 - val_loss: 1.3738\n",
            "Epoch 71/100\n",
            "14/14 [==============================] - 10s 749ms/step - loss: 1.3856 - val_loss: 1.3850\n",
            "Epoch 72/100\n",
            "14/14 [==============================] - 10s 749ms/step - loss: 1.3864 - val_loss: 1.3102\n",
            "Epoch 73/100\n",
            "14/14 [==============================] - 10s 750ms/step - loss: 1.3647 - val_loss: 1.3334\n",
            "Epoch 74/100\n",
            "14/14 [==============================] - 10s 749ms/step - loss: 1.3740 - val_loss: 1.3498\n",
            "Epoch 75/100\n",
            "14/14 [==============================] - 10s 749ms/step - loss: 1.3843 - val_loss: 1.3203\n",
            "Epoch 76/100\n",
            "14/14 [==============================] - 10s 750ms/step - loss: 1.3501 - val_loss: 1.3273\n",
            "Epoch 77/100\n",
            "14/14 [==============================] - 10s 749ms/step - loss: 1.3631 - val_loss: 1.3429\n",
            "Epoch 78/100\n",
            "14/14 [==============================] - 10s 750ms/step - loss: 1.3586 - val_loss: 1.3303\n",
            "Epoch 79/100\n",
            "14/14 [==============================] - 10s 749ms/step - loss: 1.3430 - val_loss: 1.3150\n",
            "Epoch 80/100\n",
            "14/14 [==============================] - 10s 749ms/step - loss: 1.3535 - val_loss: 1.3918\n",
            "Epoch 81/100\n",
            "14/14 [==============================] - 10s 750ms/step - loss: 1.3679 - val_loss: 1.3856\n",
            "Epoch 82/100\n",
            "14/14 [==============================] - 10s 749ms/step - loss: 1.3681 - val_loss: 1.3148\n",
            "Epoch 83/100\n",
            "14/14 [==============================] - 10s 749ms/step - loss: 1.3463 - val_loss: 1.3410\n",
            "Epoch 84/100\n",
            "14/14 [==============================] - 10s 751ms/step - loss: 1.3689 - val_loss: 1.3318\n",
            "Epoch 85/100\n",
            "14/14 [==============================] - 10s 750ms/step - loss: 1.3445 - val_loss: 1.2836\n",
            "Epoch 86/100\n",
            "14/14 [==============================] - 10s 748ms/step - loss: 1.3346 - val_loss: 1.3132\n",
            "Epoch 87/100\n",
            "14/14 [==============================] - 10s 749ms/step - loss: 1.3412 - val_loss: 1.2859\n",
            "Epoch 88/100\n",
            "14/14 [==============================] - 10s 749ms/step - loss: 1.3457 - val_loss: 1.2752\n",
            "Epoch 89/100\n",
            "14/14 [==============================] - 10s 750ms/step - loss: 1.3328 - val_loss: 1.3100\n",
            "Epoch 90/100\n",
            "14/14 [==============================] - 10s 747ms/step - loss: 1.3361 - val_loss: 1.3276\n",
            "Epoch 91/100\n",
            "14/14 [==============================] - 10s 750ms/step - loss: 1.3430 - val_loss: 1.3020\n",
            "Epoch 92/100\n",
            "14/14 [==============================] - 10s 749ms/step - loss: 1.3509 - val_loss: 1.4070\n",
            "Epoch 93/100\n",
            "14/14 [==============================] - 10s 750ms/step - loss: 1.3566 - val_loss: 1.3209\n",
            "Epoch 94/100\n",
            "14/14 [==============================] - 10s 749ms/step - loss: 1.3266 - val_loss: 1.2741\n",
            "Epoch 95/100\n",
            "14/14 [==============================] - 10s 751ms/step - loss: 1.3086 - val_loss: 1.3327\n",
            "Epoch 96/100\n",
            "14/14 [==============================] - 10s 749ms/step - loss: 1.3152 - val_loss: 1.2721\n",
            "Epoch 97/100\n",
            "14/14 [==============================] - 10s 749ms/step - loss: 1.3219 - val_loss: 1.2571\n",
            "Epoch 98/100\n",
            "14/14 [==============================] - 10s 751ms/step - loss: 1.3257 - val_loss: 1.2863\n",
            "Epoch 99/100\n",
            "14/14 [==============================] - 10s 750ms/step - loss: 1.3190 - val_loss: 1.2854\n",
            "Epoch 100/100\n",
            "14/14 [==============================] - 10s 750ms/step - loss: 1.3100 - val_loss: 1.2393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "LgfntiQUXpuB",
        "outputId": "e201bf40-d9ac-438d-cbec-32fc72c4f750"
      },
      "source": [
        "plt.plot(hist.history['loss'], label='Train loss')\n",
        "plt.plot(hist.history['val_loss'], label = 'Test loss')\n",
        "plt.legend()\n",
        "plt.title(\"Loss history\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.show()\n",
        "\n",
        "pred = model.predict(x_test)\n",
        "y_pred = np.argmax(pred, axis=1).reshape(-1, 1)\n",
        "accuracy = (y_pred == y_test).mean()\n",
        "print(\"\\nAccuracy = %.2f %s\" % (accuracy * 100, '%'))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "\n",
            "Accuracy = 62.63 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}