## NLP_study

### 자연어 처리란?


> 자연어(natural language)란 우리가 일상 생활에서 사용하는 언어를 말합니다. 자연어 처리(natural language processing)란 이러한 자연어의 의미를 분석하여 컴퓨터가 처리할 수 있도록 하는 일을 말합니다. 
> 자연어 처리는 음성 인식, 내용 요약, 번역, 사용자의 감성 분석, 텍스트 분류 작업(스팸 메일 분류, 뉴스 기사 카테고리 분류), 질의 응답 시스템, 챗봇과 같은 곳에서 사용되는 분야입니다. 
> 최근 딥 러닝이 주목을 받으면서, 인공지능이 IT 분야에서 중요 키워드로 떠오르고 있습니다. 자연어 처리는 기계에게 인간의 언어를 이해시킨다는 점에서 인공지능에 있어서 가장 중요한 연구 분야이면서도, 아직도 정복되어야 할 산이 많은 분야입니다. 
> 이 책에서는 자연어 처리에 필요한 전처리 방법(preprocessing), 딥 러닝 이전에 주류로 사용되었던 통계 기반의 언어 모델, 그리고 자연어 처리의 비약적인 성능을 이루어낸 딥 러닝을 이용한 자연어 처리에 대한 전반적인 지식을 다룹니다.

URL: [위키독스](https://wikidocs.net/21667)


## BERT

### 1. NLP에서의 사전 훈련(Pre-training)

#### 1) 사전 훈련된 워드 임베딩

  임베딩을 사용하는 방법으로는 두 가지가 있습니다. 임베딩 층(Embedding layer)를 랜덤 초기화해서 처음부터 학습하는 방법과 방대한 데이터로 Word2Vec 등과 같은 임베딩 알고리즘으로 이미 학습된 임베딩 벡터들을 사용하여 학습시키는 방법입니다. 만약에 데이터가 적은 테스크에서 사전 훈련된 임베딩을 사용하면 성능을 높일 수 있습니다. 

기존 임베딩 벡터는 아래 그림과 같이 하나의 단어가 각각 하나의 벡터값으로 맵핑되므로 문맥을 고려하지 못하는 문제점이 있었습니다. 또한, 다의어나 동음이의어를 구분하지는 못하는 문제점도 있었습니다. 예를 들어, 한국어에는 '사과🍎'라는 단어가 먹는 과일의 의미도 있고, 용서를 빈다는 의미로도 사용됩니다. 그러나 기존 임베딩 벡터는 '사과'라는 벡터에 벡터값 한개를 맵핑하므로 두 가지 의미를 구분할 수 없었습니다.

![1 PNG](https://user-images.githubusercontent.com/87213815/132116831-02f11b33-3bdd-45bf-b4fa-84fe3478cb53.png)

